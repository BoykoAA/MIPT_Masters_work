{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "import sys\n",
    "sys.path.insert(1, 'scripts/')\n",
    "from gen_matrix import matrix_gen, get_ICA\n",
    "from get_sample import get_sample, create_strings_for_dataset\n",
    "from fft import fft_for_sample\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "%matplotlib inline\n",
    "\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import operator\n",
    "\n",
    "import mne\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/alexandr/Documents/Git/MIPT_Masters_work/data/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/alexandr/Documents/Git/MIPT_Masters_work/data/S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/alexandr/Documents/Git/MIPT_Masters_work/data/S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n"
     ]
    }
   ],
   "source": [
    "raw_fnames = ['data/S001R06.edf',\n",
    "              'data/S001R10.edf',\n",
    "              'data/S001R14.edf']\n",
    "\n",
    "raw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "\n",
    "eegbci.standardize(raw)  # set channel names\n",
    "montage = make_standard_montage('standard_1005')\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# strip channel names of \".\" characters\n",
    "raw.rename_channels(lambda x: x.strip('.'))\n",
    "\n",
    "eegbci.standardize(raw)  # set channel names\n",
    "montage = make_standard_montage('standard_1005')\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# strip channel names of \".\" characters\n",
    "raw.rename_channels(lambda x: x.strip('.'))\n",
    "\n",
    "ch_name_dict = {}\n",
    "\n",
    "for i in range(0, 64):\n",
    "    ch_name_dict[i] = raw.ch_names[i]\n",
    "\n",
    "name_ch_dict = {}\n",
    "for idx, i in enumerate(raw.ch_names):\n",
    "    name_ch_dict[i] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fnames = ['data/S001R06.edf',\n",
    "              'data/S001R10.edf',\n",
    "              'data/S001R14.edf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_eeg(raw_name_path, name):\n",
    "    raw0 = read_raw_edf(raw_name_path, preload=True)\n",
    "    eegbci.standardize(raw0)\n",
    "    montage = make_standard_montage('standard_1005')\n",
    "    raw0.set_montage(montage)\n",
    "    raw0.rename_channels(lambda x: x.strip('.'))\n",
    "    raw0.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "    \n",
    "    eeg1 = raw0.get_data()\n",
    "    \n",
    "    with open(f'data/S001/{name}_onsets_start.txt', 'r') as fin:\n",
    "        start = list(map(lambda x: float(x.strip('\\n')), fin.readlines()))\n",
    "    \n",
    "    with open(f'data/S001/{name}_onsets_end.txt', 'r') as fin:\n",
    "        end = list(map(lambda x: float(x.strip('\\n')), fin.readlines()))\n",
    "\n",
    "    with open(f'data/S001/{name}_labels.txt', 'r') as fin:\n",
    "        labels = list(map(lambda x: int(x.strip('\\n')), fin.readlines()))\n",
    "        \n",
    "    one_colums_sec = end[-1] / eeg1.shape[1]\n",
    "    \n",
    "    eeg1_0 = np.zeros((64, 20000))\n",
    "    eeg1_1 = np.zeros((64, 20000))\n",
    "    eeg1_2 = np.zeros((64, 20000))\n",
    "\n",
    "    for s,e,l in zip(start, end, labels):\n",
    "        columns_start = round(s / one_colums_sec)\n",
    "        columns_end = round(e / one_colums_sec)\n",
    "        \n",
    "        if columns_start == 1:\n",
    "            columns_start -= 1\n",
    "\n",
    "        if l == 0:\n",
    "            eeg1_0[:, columns_start:columns_end] = eeg1[:, columns_start:columns_end]\n",
    "        elif l == 1:\n",
    "            eeg1_1[:, columns_start:columns_end] = eeg1[:, columns_start:columns_end]\n",
    "        elif l == 2:\n",
    "            eeg1_2[:, columns_start:columns_end] = eeg1[:, columns_start:columns_end]\n",
    "\n",
    "            \n",
    "    eeg1_0  = pd.DataFrame(eeg1_0)\n",
    "    eeg1_1 = pd.DataFrame(eeg1_1)\n",
    "    eeg1_2 = pd.DataFrame(eeg1_2)\n",
    "\n",
    "    eeg1_0 = eeg1_0.loc[:, (eeg1_0 != 0).any(axis=0)]\n",
    "    eeg1_1 = eeg1_1.loc[:, (eeg1_1 != 0).any(axis=0)]\n",
    "    eeg1_2 = eeg1_2.loc[:, (eeg1_2 != 0).any(axis=0)]\n",
    "    \n",
    "    return eeg1_0, eeg1_1, eeg1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/alexandr/Documents/Git/MIPT_Masters_work/data/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n",
      "Extracting EDF parameters from /Users/alexandr/Documents/Git/MIPT_Masters_work/data/S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n",
      "Extracting EDF parameters from /Users/alexandr/Documents/Git/MIPT_Masters_work/data/S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n",
      "(64, 10120) (64, 4612) (64, 5268)\n",
      "(64, 10120) (64, 4609) (64, 5271)\n",
      "(64, 10120) (64, 4611) (64, 5269)\n",
      "20000 20000 20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 60000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1_0, eeg1_1, eeg1_2 = get_class_eeg(raw_fnames[0], 'S001R06')\n",
    "eeg2_0, eeg2_1, eeg2_2 = get_class_eeg(raw_fnames[1], 'S001R10')\n",
    "eeg3_0, eeg3_1, eeg3_2 = get_class_eeg(raw_fnames[2], 'S001R14')\n",
    "\n",
    "print(eeg1_0.shape, eeg1_1.shape, eeg1_2.shape)\n",
    "print(eeg2_0.shape, eeg2_1.shape, eeg2_2.shape)\n",
    "print(eeg3_0.shape, eeg3_1.shape, eeg3_2.shape)\n",
    "\n",
    "print(eeg1_0.shape[1] + eeg1_1.shape[1] + eeg1_2.shape[1],\n",
    "eeg2_0.shape[1] + eeg2_1.shape[1] + eeg2_2.shape[1],\n",
    "eeg2_0.shape[1] + eeg2_1.shape[1] + eeg2_2.shape[1])\n",
    "\n",
    "eeg_class0 = pd.concat([eeg1_0, eeg2_0, eeg3_0], axis=1)\n",
    "eeg_class1 = pd.concat([eeg1_1, eeg2_1, eeg3_1], axis=1)\n",
    "eeg_class2 = pd.concat([eeg1_2, eeg2_2, eeg3_2], axis=1)\n",
    "\n",
    "class_0 = eeg_class0.shape[1]\n",
    "class_1 = eeg_class1.shape[1]\n",
    "class_2 = eeg_class2.shape[1]\n",
    "\n",
    "EEG = pd.concat([eeg_class0, eeg_class1, eeg_class2], axis=1)\n",
    "EEG.columns = list(map(lambda x: str(x), np.arange(0, 60000)))\n",
    "EEG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_on_chanells(EEG, channel_names, eeg_class0, eeg_class1, eeg_class2):\n",
    "\n",
    "    ch_number_0 = [name_ch_dict[i] for i in channel_names]\n",
    "    EEG = EEG.loc[ch_number_0, :]\n",
    "    matrix = EEG\n",
    "    size = matrix.shape\n",
    "    class_0 = eeg_class0.shape[1]\n",
    "    class_1 = eeg_class1.shape[1]\n",
    "    class_2 = eeg_class2.shape[1]\n",
    "\n",
    "\n",
    "    CHANALS = EEG.shape[0]\n",
    "    N_COMPONENTS_PCA = int(EEG.shape[0] / 2)\n",
    "    FREQ = 160\n",
    "\n",
    "    TIME_SEC = 373.5\n",
    "\n",
    "    TIME_SIZE_SEC = 2\n",
    "    STEP_TIME_SEC = 1\n",
    "\n",
    "    SAMPLE_SIZE = TIME_SIZE_SEC * FREQ\n",
    "    STEP_TIME = STEP_TIME_SEC * FREQ\n",
    "\n",
    "    LINSPACE = 0, TIME_SEC, FREQ*TIME_SEC\n",
    "\n",
    "    from sklearn.decomposition import FastICA\n",
    "\n",
    "    FastICA = FastICA(n_components=CHANALS).fit(matrix.T)\n",
    "    ICA = FastICA.transform(matrix.T)\n",
    "\n",
    "    matrix = ICA.T\n",
    "\n",
    "    matrix_class1 = matrix[:, 0:class_0]\n",
    "    matrix_calss2 = matrix[:, class_0:class_0+class_1]\n",
    "    matrix_calss3 = matrix[:, class_0+class_1:class_0+class_1+class_2]\n",
    "    #Получаем семплы для каждого класса\n",
    "    sample_calss1 = get_sample(matrix_class1, sample_size=SAMPLE_SIZE, step=STEP_TIME)\n",
    "    sample_calss2 = get_sample(matrix_calss2, sample_size=SAMPLE_SIZE, step=STEP_TIME)\n",
    "    sample_calss3 = get_sample(matrix_calss3, sample_size=SAMPLE_SIZE, step=STEP_TIME)\n",
    "\n",
    "    i_ = 0\n",
    "    for i in range(len(sample_calss1)):\n",
    "        for j in range(sample_calss1[0].shape[0]):\n",
    "            #print(sample_calss1[i][j].shape[0])\n",
    "            if sample_calss1[i][j].shape[0] != SAMPLE_SIZE:\n",
    "                if i_ == 0:\n",
    "                    i_ = i\n",
    "\n",
    "    sample_calss1 = sample_calss1[:i_]\n",
    "    sample_calss2 = sample_calss2[:i_]\n",
    "    sample_calss3 = sample_calss3[:i_]\n",
    "\n",
    "    samples_fft = list(fft_for_sample(sample_calss1 + sample_calss2 + sample_calss3, freq=FREQ, lowFreq=7, highFreq=30))\n",
    "\n",
    "    len_class_1 = len(sample_calss1)\n",
    "    len_class_2 = len(sample_calss2)\n",
    "    len_class_3 = len(sample_calss3)\n",
    "\n",
    "    sample_calss1_fft = samples_fft[:len_class_1]\n",
    "    sample_calss2_fft = samples_fft[len_class_1:len_class_1 + len_class_2]\n",
    "    sample_calss3_fft = samples_fft[len_class_1 + len_class_2:len_class_1 + len_class_2 + len_class_3]\n",
    "\n",
    "\n",
    "    FIRST_N_FFT = len(sample_calss1_fft[0][0])\n",
    "\n",
    "    #Создание строк для датасета, из матрицы CHANALS*FIRST_N_FFT -> в вектор\n",
    "    sample_calss1_fft_str = create_strings_for_dataset(sample_calss1_fft)\n",
    "    sample_calss2_fft_str = create_strings_for_dataset(sample_calss2_fft)\n",
    "    sample_calss3_fft_str = create_strings_for_dataset(sample_calss3_fft)\n",
    "\n",
    "\n",
    "\n",
    "    #Создание таблицы объекты-признаки\n",
    "\n",
    "    #Класс 1\n",
    "    data_class_1 = pd.DataFrame(data=np.zeros((len_class_1, size[0] * FIRST_N_FFT)))\n",
    "    data_class_1['label'] = 1\n",
    "\n",
    "    data_class_1 = np.array(data_class_1)\n",
    "\n",
    "    for i in(range(len(sample_calss1_fft_str))):\n",
    "        data_class_1[i, :-1] = sample_calss1_fft_str[i]\n",
    "\n",
    "\n",
    "    #Класс 2\n",
    "    data_class_2 = pd.DataFrame(data=np.zeros((len_class_2 - 3, size[0] * FIRST_N_FFT))) #!!!!!!\n",
    "    data_class_2['label'] = 2\n",
    "\n",
    "    data_class_2 = np.array(data_class_2)\n",
    "\n",
    "    for i in (range(len(sample_calss2_fft_str) - 3)): #!!!!!!!!!\n",
    "        data_class_2[i, :-1] = sample_calss2_fft_str[i]\n",
    "\n",
    "\n",
    "    #Класс 3\n",
    "    data_class_3 = pd.DataFrame(data=np.zeros((len_class_3 - 1, size[0] * FIRST_N_FFT))) #####!!!!!!\n",
    "    data_class_3['label'] = 3\n",
    "\n",
    "    data_class_3 = np.array(data_class_3)\n",
    "\n",
    "    for i in (range(len(sample_calss3_fft_str) - 1)): #####!!!!\n",
    "        data_class_3[i, :-1] = sample_calss3_fft_str[i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data = np.vstack([data_class_1, data_class_2, data_class_3])\n",
    "    data = pd.DataFrame(data)\n",
    "    print(data.shape)\n",
    "    data.columns = [*data.columns[:-1], 'label']\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data['label']\n",
    "    \n",
    "    from sklearn.decomposition import PCA\n",
    "    PCA = PCA(n_components=len(channel_names) // 2, random_state=100)\n",
    "\n",
    "    # Понижаем размерность\n",
    "    X = PCA.fit_transform(X)\n",
    "    print(X.shape)\n",
    "    rf = RandomForestClassifier()\n",
    "    print(f'score: {np.mean(cross_val_score(rf, X, y, cv=3))} on channels: {channel_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best channels:\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.43213467301251535 on channels: ['O2', 'C3', 'C4']\n",
      "other channels:\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.3595099594570774 on channels: ['Fp1', 'P6', 'F1']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.4078970562312709 on channels: ['Fpz', 'AFz', 'AF3']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.33505200070509433 on channels: ['P4', 'O1', 'P5']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.3866120218579235 on channels: ['AF7', 'AF3', 'F7']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.4082936717786004 on channels: ['P4', 'PO7', 'FT7']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.4569011105235325 on channels: ['F6', 'Iz', 'Pz']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.3620218579234973 on channels: ['P6', 'Fpz', 'AFz']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.394632469592808 on channels: ['P7', 'Fz', 'P5']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.39432399083377406 on channels: ['PO3', 'PO4', 'POz']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.3811034725894588 on channels: ['F4', 'P3', 'Fpz']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.47563017803631236 on channels: ['P6', 'AF8', 'F7']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.4241142252776309 on channels: ['PO8', 'P7', 'P8']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.39745284681826193 on channels: ['P1', 'F1', 'Iz']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.4784505552617662 on channels: ['Oz', 'PO7', 'PO8']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.3866560902520712 on channels: ['P8', 'P4', 'AF7']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.4109377754274634 on channels: ['FT7', 'AF3', 'PO4']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.402741054115988 on channels: ['AF3', 'PO8', 'Fp1']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.3864798166754803 on channels: ['F7', 'PO3', 'PO8']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.38881544156530934 on channels: ['FT8', 'P7', 'PO8']\n",
      "(370, 220)\n",
      "(370, 1)\n",
      "score: 0.33214348669134497 on channels: ['PO8', 'AF8', 'Fz']\n",
      "\n",
      "best channels:\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.5403225806451614 on channels: ['O2', 'FC4', 'C3', 'FCz']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.5077560373699982 on channels: ['O2', 'T8', 'FC4', 'C3']\n",
      "other channels:\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.43473470826723076 on channels: ['O1', 'Fp1', 'F3', 'F7']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.357086197778953 on channels: ['TP8', 'FT8', 'T8', 'F8']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.4132734003172924 on channels: ['POz', 'AF7', 'F5', 'AF3']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.4246871144015512 on channels: ['Fpz', 'T8', 'FT8', 'P1']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.4484840472413185 on channels: ['POz', 'Fp2', 'F4', 'FT7']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.3892120571126388 on channels: ['P8', 'Pz', 'F6', 'Fz']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.43248722016569713 on channels: ['F5', 'Fz', 'P7', 'F1']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.43248722016569713 on channels: ['P8', 'Fp2', 'Fz', 'F6']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.370174510840825 on channels: ['AF3', 'TP8', 'P1', 'Fp1']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.48083024854574297 on channels: ['PO3', 'AF7', 'F4', 'PO8']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.4325753569539926 on channels: ['FT8', 'AF4', 'AF3', 'T10']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.5190375462718139 on channels: ['AF8', 'P7', 'F5', 'T10']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.4755861096421647 on channels: ['AF7', 'P1', 'Fp2', 'F2']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.4460602855631941 on channels: ['F4', 'T9', 'F8', 'T10']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.37837123215230034 on channels: ['P1', 'P8', 'F7', 'AF7']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.402741054115988 on channels: ['FT7', 'O1', 'T7', 'Iz']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.4539044597214878 on channels: ['F2', 'Oz', 'Fp2', 'F5']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.44861625242376163 on channels: ['AF8', 'F8', 'AF3', 'Iz']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.45936894059580463 on channels: ['Pz', 'PO8', 'AF3', 'F5']\n",
      "(370, 293)\n",
      "(370, 2)\n",
      "score: 0.4245108408249603 on channels: ['AF3', 'Fp2', 'P8', 'AF7']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "channel_names_BEST = ['O2', 'C3', 'C4']\n",
    "dont_best = [i for i in list(name_ch_dict.keys()) if i not in channel_names_BEST]\n",
    "dont_best = [i for i in dont_best if i[0] != 'C' and i[0] != 'T' and i[:2] != 'FC']\n",
    "print('best channels:')\n",
    "get_score_on_chanells(EEG, channel_names_BEST, eeg_class0, eeg_class1, eeg_class2)\n",
    "print('other channels:')\n",
    "for _ in range(20):\n",
    "    channels = random.sample(dont_best, len(channel_names_BEST))\n",
    "    get_score_on_chanells(EEG, channels, eeg_class0, eeg_class1, eeg_class2)\n",
    "    \n",
    "print()\n",
    "    \n",
    "channel_names_BEST = ['O2', 'FC4', 'C3', 'FCz']\n",
    "channel_names_BEST1 = ['O2','T8','FC4','C3']\n",
    "dont_best = [i for i in list(name_ch_dict.keys()) if i not in channel_names_BEST]\n",
    "dont_best = [i for i in dont_best if i[0] != 'C' and i[:2] != 'FC']\n",
    "print('best channels:')\n",
    "get_score_on_chanells(EEG, channel_names_BEST, eeg_class0, eeg_class1, eeg_class2)\n",
    "get_score_on_chanells(EEG, channel_names_BEST1, eeg_class0, eeg_class1, eeg_class2)\n",
    "print('other channels:')\n",
    "for _ in range(20):\n",
    "    channels = random.sample(dont_best, len(channel_names_BEST))\n",
    "    get_score_on_chanells(EEG, channels, eeg_class0, eeg_class1, eeg_class2)\n",
    "    \n",
    "print()\n",
    "    \n",
    "# channel_names_BEST = ['P2','O2','C3','C6','Fp1','P5','C4']\n",
    "# channel_names_BEST1 = ['O2','Fp1','C3','F5','P2','C4']\n",
    "# dont_best = [i for i in list(name_ch_dict.keys()) if i not in channel_names_BEST]\n",
    "# dont_best = [i for i in dont_best if i[0] != 'C' and i[:2] != 'FC']\n",
    "# print('best channels:')\n",
    "# get_score_on_chanells(EEG, channel_names_BEST, eeg_class0, eeg_class1, eeg_class2)\n",
    "# get_score_on_chanells(EEG, channel_names_BEST1, eeg_class0, eeg_class1, eeg_class2)\n",
    "# print('other channels:')\n",
    "# for _ in range(20):\n",
    "#     channels = random.sample(dont_best, len(channel_names_BEST))\n",
    "#     get_score_on_chanells(EEG, channels, eeg_class0, eeg_class1, eeg_class2)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
